# CorrectNav

Existing vision-and-language navigation models often struggle to recover from trajectory errors due to limited correction capabilities. To address this, we propose Self-correction Flywheel, a novel post-training paradigm that treats error trajectories as valuable training data. Our method automatically detects deviations and generates self-correction data for perception and action, fueling continuous model improvement. Through iterative flywheel cycles, we progressively enhance our monocular RGB-based VLA model, CorrectNav.
